//#include <opencv2/opencv.hpp>
#include "WPILib.h"

#include <thread>

#include <CameraServer.h>
#include <IterativeRobot.h>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/core/core.hpp>
#include <opencv2/core/types.hpp>

// Include Pipeline class generated by GRIP
#include "Pipeline.h"

const int counterIterator = 2;

class IntermediateVisionRobot : public frc::SampleRobot
{
	bool hassavedframe;
	int robotCounter;
	Pipeline pipeline;

private:
	static void USBVisionThread() {

		// Get the USB camera from CameraServer
		// Using default cam0
		cs::UsbCamera camera = CameraServer::GetInstance()->StartAutomaticCapture();
		// Set the resolution
		camera.SetResolution(640, 480);

		// Get a CvSink. This will capture Mats from the Camera
		cs::CvSink cvSink = CameraServer::GetInstance()->GetVideo();
		// Setup a CvSource. This will send images back to the Dashboard
		cs::CvSource outputStream = CameraServer::GetInstance()->
				PutVideo("USBFeed", 640, 480);

		// Mats are very memory expensive. Lets reuse this Mat.
		cv::Mat mat;

		// Set up Pipeline
		Pipeline pipel;

		while (true) { 		// May need to end vision while disabled
			// Tell the CvSink to grab a frame from the camera and put it in the source mat.  If there is an error notify the output.
			if (cvSink.GrabFrame(mat) == 0) {
				// Send the output the error.
				outputStream.NotifyError(cvSink.GetError());
				// skip the rest of the current iteration
				continue;
			}
			// Put a rectangle on the image
			rectangle(mat, cv::Point(100, 100), cv::Point(400, 400),cv::Scalar(255, 255, 255), 5);


			// Set pipeline source
			pipel.setsource0(mat);
			pipel.Process();

			int temp = ((*(pipel.getfindContoursOutput()))[0][0]).x;
			string tempString = std::to_string(temp);
			cv::putText(mat, tempString, cv::Point(10,50), cv::FONT_HERSHEY_SIMPLEX, 1, cv::Scalar(255,255,0));

			// Give the output stream a new image to display
			outputStream.PutFrame(mat);
		}
	}

	static void HTTPVisionThread() {

		// Using a MJPEG streamer through HTTP
		llvm::StringRef name = "RPi";
		llvm::StringRef url = "http://raspberrypi.local:8080/?action=stream";
		cs::HttpCamera camera(name,url,cs::HttpCamera::HttpCameraKind::kMJPGStreamer);
		// Set the resolution
		camera.SetResolution(640, 480);
		camera.SetPixelFormat(cs::VideoMode::PixelFormat::kYUYV);
		// Add camera to cameraserver
		CameraServer::GetInstance()->AddCamera(camera);

		// Get a CvSink. This will capture Mats from the Camera
		cs::CvSink cvSink = CameraServer::GetInstance()->GetVideo();
		// Setup a CvSource. This will send images back to the Dashboard
		cs::CvSource outputStream = CameraServer::GetInstance()->
				PutVideo("RPiFeed", 640, 480);

		// Mats are very memory expensive. Lets reuse this Mat.
		cv::Mat mat;

		// Set up Pipeline
		Pipeline pipel;

		while (true) { 		// May need to end vision while disabled
			// Tell the CvSink to grab a frame from the camera and put it in the source mat.  If there is an error notify the output.
			if (cvSink.GrabFrame(mat) == 0) {
				// Send the output the error.
				outputStream.NotifyError(cvSink.GetError());
				// skip the rest of the current iteration
				continue;
			}

			// Set pipeline source
			pipel.setsource0(mat);
			pipel.Process();

			int temp = ((*(pipel.getfindContoursOutput()))[0][0]).x;
			string tempString = std::to_string(temp);
			cv::putText(mat, tempString, cv::Point(10,50), cv::FONT_HERSHEY_SIMPLEX, 1, cv::Scalar(255,255,0));

			// Give the output stream a new image to display
			outputStream.PutFrame(mat);
		}
	}

	// Under testing
	static void AxisVisionThread() {

			// Using an Axis camera
			llvm::StringRef name = "Axis";
			llvm::StringRef url = "axis-camera.localm";
			cs::AxisCamera camera(name,url);
			// Set the resolution
			camera.SetResolution(640, 480);
			// Add camera to cameraserver
			CameraServer::GetInstance()->AddCamera(camera);

			// Get a CvSink. This will capture Mats from the Camera
			cs::CvSink cvSink = CameraServer::GetInstance()->GetVideo();
			// Setup a CvSource. This will send images back to the Dashboard
			cs::CvSource outputStream = CameraServer::GetInstance()->
					PutVideo("AxisFeed", 640, 480);

			// Mats are very memory expensive. Lets reuse this Mat.
			cv::Mat mat;

			// Set up Pipeline
			Pipeline pipel;

			while (true) { 		// May need to end vision while disabled
				// Tell the CvSink to grab a frame from the camera and put it in the source mat.  If there is an error notify the output.
				if (cvSink.GrabFrame(mat) == 0) {
					// Send the output the error.
					outputStream.NotifyError(cvSink.GetError());
					// skip the rest of the current iteration
					continue;
				}

				// Set pipeline source
				pipel.setsource0(mat);
				pipel.Process();

				int temp = ((*(pipel.getfindContoursOutput()))[0][0]).x;
				string tempString = std::to_string(temp);
				cv::putText(mat, tempString, cv::Point(10,50), cv::FONT_HERSHEY_SIMPLEX, 1, cv::Scalar(255,255,0));

				// Give the output stream a new image to display
				outputStream.PutFrame(mat);
			}
	}

public:
	void RobotInit() override {

		std::thread usbvisionThread(USBVisionThread);
		std::thread httpvisionThread(HTTPVisionThread);
		std::thread axisvisionThread(AxisVisionThread);
		usbvisionThread.detach();
		httpvisionThread.detach();
		axisvisionThread.detach();

		robotCounter = 0;
	}

	void Disabled() override {
		hassavedframe = true;

		robotCounter = 0;
	}

	void OperatorControl() override {

		DriverStation::ReportError("Now in operateControl Method \n");
	}
};

START_ROBOT_CLASS(IntermediateVisionRobot)

